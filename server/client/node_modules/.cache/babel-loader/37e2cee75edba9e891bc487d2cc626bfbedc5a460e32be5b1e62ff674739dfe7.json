{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport var content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n/** @type {Construct} */\n\nvar continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  var previous;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    effects.enter('content');\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    });\n    return data(code);\n  }\n  /** @type {State} */\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n    effects.consume(code);\n    return data;\n  }\n  /** @type {State} */\n\n  function contentEnd(code) {\n    effects.exit('chunkContent');\n    effects.exit('content');\n    return ok(code);\n  }\n  /** @type {State} */\n\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit('chunkContent');\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    });\n    previous = previous.next;\n    return data;\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  var self = this;\n  return startLookahead;\n  /** @type {State} */\n\n  function startLookahead(code) {\n    effects.exit('chunkContent');\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, prefixed, 'linePrefix');\n  }\n  /** @type {State} */\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n    var tail = self.events[self.events.length - 1];\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === 'linePrefix' && tail[2].sliceSerialize(tail[1], true).length >= 4) {\n      return ok(code);\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","map":{"version":3,"names":["factorySpace","markdownLineEnding","subtokenize","content","tokenize","tokenizeContent","resolve","resolveContent","continuationConstruct","tokenizeContinuation","partial","events","effects","ok","previous","start","code","enter","contentType","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","prefixed","tail","length","parser","constructs","disable","null","includes","type","sliceSerialize","interrupt","flow"],"sources":["/home/kty/workspace/seb41_pre_001/client/node_modules/micromark-core-commonmark/lib/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n}\n/** @type {Construct} */\n\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n}\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return data(code)\n  }\n  /** @type {State} */\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n  /** @type {State} */\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n  /** @type {State} */\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    })\n    previous = previous.next\n    return data\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this\n  return startLookahead\n  /** @type {State} */\n\n  function startLookahead(code) {\n    effects.exit('chunkContent')\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n  /** @type {State} */\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    const tail = self.events[self.events.length - 1]\n\n    if (\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\n      tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n    ) {\n      return ok(code)\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n  }\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAQA,YAAY,QAAO,yBAAyB;AACpD,SAAQC,kBAAkB,QAAO,0BAA0B;AAC3D,SAAQC,WAAW,QAAO,4BAA4B;;AAEtD;AACA;AACA;AACA;AACA,OAAO,IAAMC,OAAO,GAAG;EACrBC,QAAQ,EAAEC,eAAe;EACzBC,OAAO,EAAEC;AACX,CAAC;AACD;;AAEA,IAAMC,qBAAqB,GAAG;EAC5BJ,QAAQ,EAAEK,oBAAoB;EAC9BC,OAAO,EAAE;AACX,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAEA,SAASH,cAAc,CAACI,MAAM,EAAE;EAC9BT,WAAW,CAACS,MAAM,CAAC;EACnB,OAAOA,MAAM;AACf;AACA;;AAEA,SAASN,eAAe,CAACO,OAAO,EAAEC,EAAE,EAAE;EACpC;EACA,IAAIC,QAAQ;EACZ,OAAOC,KAAK;EACZ;;EAEA,SAASA,KAAK,CAACC,IAAI,EAAE;IACnBJ,OAAO,CAACK,KAAK,CAAC,SAAS,CAAC;IACxBH,QAAQ,GAAGF,OAAO,CAACK,KAAK,CAAC,cAAc,EAAE;MACvCC,WAAW,EAAE;IACf,CAAC,CAAC;IACF,OAAOC,IAAI,CAACH,IAAI,CAAC;EACnB;EACA;;EAEA,SAASG,IAAI,CAACH,IAAI,EAAE;IAClB,IAAIA,IAAI,KAAK,IAAI,EAAE;MACjB,OAAOI,UAAU,CAACJ,IAAI,CAAC;IACzB;IAEA,IAAIf,kBAAkB,CAACe,IAAI,CAAC,EAAE;MAC5B,OAAOJ,OAAO,CAACS,KAAK,CAClBb,qBAAqB,EACrBc,eAAe,EACfF,UAAU,CACX,CAACJ,IAAI,CAAC;IACT,CAAC,CAAC;;IAEFJ,OAAO,CAACW,OAAO,CAACP,IAAI,CAAC;IACrB,OAAOG,IAAI;EACb;EACA;;EAEA,SAASC,UAAU,CAACJ,IAAI,EAAE;IACxBJ,OAAO,CAACY,IAAI,CAAC,cAAc,CAAC;IAC5BZ,OAAO,CAACY,IAAI,CAAC,SAAS,CAAC;IACvB,OAAOX,EAAE,CAACG,IAAI,CAAC;EACjB;EACA;;EAEA,SAASM,eAAe,CAACN,IAAI,EAAE;IAC7BJ,OAAO,CAACW,OAAO,CAACP,IAAI,CAAC;IACrBJ,OAAO,CAACY,IAAI,CAAC,cAAc,CAAC;IAC5BV,QAAQ,CAACW,IAAI,GAAGb,OAAO,CAACK,KAAK,CAAC,cAAc,EAAE;MAC5CC,WAAW,EAAE,SAAS;MACtBJ,QAAQ,EAARA;IACF,CAAC,CAAC;IACFA,QAAQ,GAAGA,QAAQ,CAACW,IAAI;IACxB,OAAON,IAAI;EACb;AACF;AACA;;AAEA,SAASV,oBAAoB,CAACG,OAAO,EAAEC,EAAE,EAAEa,GAAG,EAAE;EAC9C,IAAMC,IAAI,GAAG,IAAI;EACjB,OAAOC,cAAc;EACrB;;EAEA,SAASA,cAAc,CAACZ,IAAI,EAAE;IAC5BJ,OAAO,CAACY,IAAI,CAAC,cAAc,CAAC;IAC5BZ,OAAO,CAACK,KAAK,CAAC,YAAY,CAAC;IAC3BL,OAAO,CAACW,OAAO,CAACP,IAAI,CAAC;IACrBJ,OAAO,CAACY,IAAI,CAAC,YAAY,CAAC;IAC1B,OAAOxB,YAAY,CAACY,OAAO,EAAEiB,QAAQ,EAAE,YAAY,CAAC;EACtD;EACA;;EAEA,SAASA,QAAQ,CAACb,IAAI,EAAE;IACtB,IAAIA,IAAI,KAAK,IAAI,IAAIf,kBAAkB,CAACe,IAAI,CAAC,EAAE;MAC7C,OAAOU,GAAG,CAACV,IAAI,CAAC;IAClB;IAEA,IAAMc,IAAI,GAAGH,IAAI,CAAChB,MAAM,CAACgB,IAAI,CAAChB,MAAM,CAACoB,MAAM,GAAG,CAAC,CAAC;IAEhD,IACE,CAACJ,IAAI,CAACK,MAAM,CAACC,UAAU,CAACC,OAAO,CAACC,IAAI,CAACC,QAAQ,CAAC,cAAc,CAAC,IAC7DN,IAAI,IACJA,IAAI,CAAC,CAAC,CAAC,CAACO,IAAI,KAAK,YAAY,IAC7BP,IAAI,CAAC,CAAC,CAAC,CAACQ,cAAc,CAACR,IAAI,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAACC,MAAM,IAAI,CAAC,EACjD;MACA,OAAOlB,EAAE,CAACG,IAAI,CAAC;IACjB;IAEA,OAAOJ,OAAO,CAAC2B,SAAS,CAACZ,IAAI,CAACK,MAAM,CAACC,UAAU,CAACO,IAAI,EAAEd,GAAG,EAAEb,EAAE,CAAC,CAACG,IAAI,CAAC;EACtE;AACF"},"metadata":{},"sourceType":"module","externalDependencies":[]}